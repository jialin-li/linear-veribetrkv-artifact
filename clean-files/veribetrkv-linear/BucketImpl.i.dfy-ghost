// BucketImpl.i.dfy
module BucketImpl {
  type TreeMap = LKMB.Model.Node
  datatype Iterator = Iterator(ghost next: BucketIteratorModel.IteratorOutput, i: uint64, ghost decreaser: int)
  datatype BucketFormat = BFTree(tree: TreeMap) | BFPkv(pkv: PackedKV.Pkv)
  datatype MutBucket = MutBucket(format: BucketFormat, weight: uint64, sorted: bool, ghost bucket: Bucket) {
    predicate Inv()
      ensures Inv() ==> weight as int == WeightBucket(bucket)
      ensures Inv() ==> WFBucket(bucket)
      decreases this
    {
      (format.BFTree? ==>
        LKMB.WF(format.tree) &&
        LKMBPKVOps.IsKeyMessageTree(format.tree) &&
        bucket == B(LKMB.Interpretation(format.tree))) &&
      (format.BFPkv? ==>
        PackedKV.WF(format.pkv) &&
        bucket == PackedKV.I(format.pkv)) &&
      WFBucket(bucket) &&
      weight as int == WeightBucket(bucket) &&
      weight as int < Uint32UpperBound() &&
      (sorted ==>
        BucketWellMarshalled(bucket))
    }
    static method Alloc() returns (mb: MutBucket)
      ensures mb.bucket == EmptyBucket()
      ensures mb.Inv()
    {
      var tmp: Node := LKMB.EmptyTree();
      mb := MutBucket(BFTree(tmp), 0, true, EmptyBucket());
      B_empty_map();
    }
    static method AllocPkv(pkv: PackedKV.Pkv, is_sorted: bool) returns (mb: MutBucket)
      requires PackedKV.WF(pkv)
      requires is_sorted ==> BucketWellMarshalled(PackedKV.I(pkv))
      requires PackedKV.WeightPkv(pkv) as nat < Uint32UpperBound()
      ensures mb.I() == PackedKV.I(pkv)
      ensures mb.Inv()
      decreases pkv, is_sorted
    {
      mb := MutBucket(BFPkv(pkv), PackedKV.WeightPkv(pkv), is_sorted, PackedKV.I(pkv));
      WeightBucketIs(pkv);
    }
    static lemma WeightKeyListIs(psa: PackedKV.PSA.Psa, k: int)
      requires PSA.WF(psa)
      requires 0 <= k <= |psa.offsets|
      requires PackedKV.ValidKeyLens(PSA.I(psa))
      ensures WeightKeyList(PackedKV.IKeys(psa)[..k]) == 4 * k + if k == 0 then 0 else PSA.psaEnd(psa, (k - 1) as uint64) as int
      decreases psa, k
    {
      if k == 0 {
      } else {
        ghost var keys: seq<Key> := PackedKV.IKeys(psa);
        ghost var weights: seq<nat> := ApplyOpaque(WeightKey, keys[..k]);
        ghost var weights': seq<nat> := ApplyOpaque(WeightKey, keys[..k - 1]);
        ghost var key: Key := keys[k - 1];
        calc == {
          WeightKeyList(keys[..k]);
        ==
          {
            assert keys[..k - 1] + [key] == keys[..k];
            WeightKeyListPushBack(keys[..k - 1], key);
          }
          WeightKey(key) + WeightKeyList(keys[..k - 1]);
        ==
          {
            WeightKeyListIs(psa, k - 1);
          }
          4 * k + PackedKV.PSA.psaEnd(psa, (k - 1) as uint64) as int;
        }
      }
    }
    static lemma WeightMessageListIs(psa: PackedKV.PSA.Psa, k: int)
      requires PSA.WF(psa)
      requires 0 <= k <= |psa.offsets|
      requires ValueType.ValidMessageBytestrings(PSA.I(psa))
      ensures WeightMessageList(PackedKV.IMessages(psa)[..k]) == 4 * k + if k == 0 then 0 else PSA.psaEnd(psa, (k - 1) as uint64) as int
      decreases psa, k
    {
      if k == 0 {
      } else {
        ghost var msgs: seq<Message> := PackedKV.IMessages(psa);
        ghost var weights: seq<nat> := ApplyOpaque(WeightMessage, msgs[..k]);
        ghost var weights': seq<nat> := ApplyOpaque(WeightMessage, msgs[..k - 1]);
        ghost var msg: Message := msgs[k - 1];
        calc == {
          WeightMessageList(msgs[..k]);
        ==
          {
            assert msgs[..k - 1] + [msg] == msgs[..k];
            WeightMessageListPushBack(msgs[..k - 1], msg);
          }
          WeightMessage(msg) + WeightMessageList(msgs[..k - 1]);
        ==
          {
            WeightMessageListIs(psa, k - 1);
          }
          {
            PackedKV.DefineIMessage(psa, k - 1);
          }
          4 * k + PackedKV.PSA.psaEnd(psa, (k - 1) as uint64) as int;
        }
      }
    }
    static lemma WeightBucketIs(pkv: PackedKV.Pkv)
      requires PackedKV.WF(pkv)
      ensures WeightBucket(PackedKV.I(pkv)) == PackedKV.WeightPkv(pkv) as int
      decreases pkv
    {
      ghost var bucket: Bucket := PackedKV.I(pkv);
      ghost var n: int := |pkv.keys.offsets|;
      ghost var keys: seq<Key> := PSA.I(pkv.keys);
      ghost var msgs: seq<Message> := PackedKV.IMessages(pkv.messages);
      assert keys == keys[0 .. n];
      assert msgs == msgs[0 .. n];
      WeightKeyListIs(pkv.keys, n);
      WeightMessageListIs(pkv.messages, n);
    }
    method GetPkvSorted(must_be_sorted: bool) returns (pkv: PKV.Pkv)
      requires Inv()
      ensures PKV.WF(pkv)
      ensures !must_be_sorted ==> PKV.I(pkv) == bucket
      ensures must_be_sorted ==> PKV.I(pkv) == B(bucket.as_map())
      ensures WeightBucket(PKV.I(pkv)) <= weight as nat
      decreases this, must_be_sorted
    {
      if format.BFTree? {
        NumElementsLteWeight(B(LKMB.Interpretation(format.tree)));
        pkv := tree_to_pkv(format.tree);
      } else if !must_be_sorted || sorted {
        pkv := this.format.pkv;
        assert PKV.WF(pkv);
        assert !must_be_sorted ==> PKV.I(pkv) == bucket;
        assert sorted ==> PKV.I(pkv) == B(bucket.as_map()) by {
          if sorted {
            B_of_as_map_sorted(bucket);
          }
        }
      } else {
        var tree: TreeMap;
        var weight: uint64;
        tree, weight := pkv_to_tree(this.format.pkv);
        BucketWeights.Weight_SortedBucket_le_UnsortedBucket(PKV.I(this.format.pkv), B(LKMB.Interpretation(tree)));
        NumElementsLteWeight(bucket);
        pkv := tree_to_pkv(tree);
        var _: () := LKMB.FreeNode(tree);
      }
    }
    method GetPkv() returns (pkv: PKV.Pkv)
      requires Inv()
      ensures PKV.WF(pkv)
      ensures PKV.I(pkv) == bucket
      decreases this
    {
      pkv := GetPkvSorted(false);
    }
    method WellMarshalled() returns (b: bool)
      requires Inv()
      ensures b == BucketWellMarshalled(I())
      decreases this
    {
      if format.BFTree? {
        b := true;
      } else {
        if sorted {
          b := true;
        } else {
          b := PackedKV.ComputeIsSorted(format.pkv);
          assert bucket.keys == PackedKV.PSA.I(format.pkv.keys);
        }
      }
    }
    method Empty() returns (result: bool)
      requires Inv()
      ensures result == (|I().keys| == 0)
      decreases this
    {
      if format.BFTree? {
        result := LKMB.Empty(format.tree);
        MapSeqs.emptiness_map_of_seqs(I().keys, I().msgs);
      } else {
        SetCardinality0(PackedKV.IKeys(format.pkv.keys));
        result := 0 == |format.pkv.keys.offsets| as uint64;
      }
    }
    method WFBucketAt(pivots: Pivots.PivotTable, i: uint64) returns (result: bool)
      requires Inv()
      requires BucketWellMarshalled(I())
      requires Pivots.WFPivots(pivots)
      requires forall k: Key {:trigger BoundedKey(pivots, k)} {:trigger k in bucket.keys} | k in bucket.keys :: BoundedKey(pivots, k)
      requires i as nat < Pivots.NumBuckets(pivots) < Uint64UpperBound()
      ensures result == BucketsLib.WFBucketAt(I(), pivots, i as nat)
      decreases this, pivots, i
    {
      var e: bool := Empty();
      if e {
        return true;
      }
      Lexicographic_Byte_Order.reveal_IsStrictlySorted();
      var firstkey: Key := GetFirstKey();
      var c: int32 := Pivots.KeyspaceImpl.cmp(pivots[i], Pivots.Keyspace.Element(firstkey));
      if 0 < c {
        return false;
      }
      var lastkey: Key := GetLastKey();
      c := Pivots.KeyspaceImpl.cmp(Pivots.Keyspace.Element(lastkey), pivots[i + 1]);
      if c >= 0 {
        return false;
      }
      return true;
    }
    static predicate InvSeq(s: seq<MutBucket>)
      ensures InvSeq(s) == forall i: int {:trigger s[i]} | 0 <= i < |s| :: s[i].Inv()
      decreases s
    {
      forall i: int {:trigger s[i]} | 0 <= i < |s| :: 
        s[i].Inv()
    }
    function I(): Bucket
      decreases this
    {
      bucket
    }
    static function {:opaque} {:fuel 0, 0} ISeq(s: seq<MutBucket>): (bs: seq<Bucket>)
      ensures |bs| == |s|
      ensures forall i: int {:trigger s[i]} {:trigger bs[i]} | 0 <= i < |s| :: bs[i] == s[i].bucket
      decreases |s|
    {
      if |s| == 0 then
        []
      else
        ISeq(DropLast(s)) + [Last(s).I()]
    }
    static lemma  ISeqInduction(s: seq<MutBucket>)
      requires |s| > 0
      ensures ISeq(s) == ISeq(DropLast(s)) + [Last(s).I()]
      decreases s
    {
    }
    static lemma  ISeq_replace1with2(buckets: seq<MutBucket>, l: MutBucket, r: MutBucket, slot: int)
      requires InvSeq(buckets)
      requires 0 <= slot < |buckets|
      requires l.Inv()
      requires r.Inv()
      ensures InvSeq(replace1with2(buckets, l, r, slot))
      ensures ISeq(replace1with2(buckets, l, r, slot)) == replace1with2(ISeq(buckets), l.I(), r.I(), slot)
      decreases buckets, l, r, slot
    {
      ghost var s: seq<MutBucket> := replace1with2(buckets, l, r, slot);
      forall i: int {:trigger replace1with2(ISeq(buckets), l.I(), r.I(), slot)[i]} {:trigger ISeq(replace1with2(buckets, l, r, slot))[i]} {:trigger s[i]} | 0 <= i < |s|
        ensures s[i].Inv() && ISeq(replace1with2(buckets, l, r, slot))[i] == replace1with2(ISeq(buckets), l.I(), r.I(), slot)[i]
      {
        if i == slot {
          assert s[i] == l;
        } else if i == slot + 1 {
          assert s[i] == r;
        } else if i < slot {
          assert s[i] == buckets[i];
        } else {
          assert s[i] == buckets[i - 1];
        }
      }
    }
    static predicate InvLseq(s: lseq<MutBucket>)
    {
      lseq_has_all(s) &&
      InvSeq(lseqs(s)) &&
      operator'cardinality?lseq(s) < Uint64UpperBound()
    }
    static function ILseq(s: lseq<MutBucket>): (bs: seq<Bucket>)
      ensures operator'cardinality?lseq(s) == |bs|
      ensures forall i: int {:trigger operator'subscript?lseq(s, i)} {:trigger bs[i]} | 0 <= i < operator'cardinality?lseq(s) :: bs[i] == operator'subscript?lseq(s, i).I()
    {
      ISeq(lseqs(s))
    }
    method GetFirstKey() returns (result: Key)
      requires Inv()
      requires BucketWellMarshalled(bucket)
      requires 0 < |bucket.keys|
      ensures result in bucket.keys
      ensures forall k: Element {:trigger lte(result, k)} {:trigger k in bucket.keys} | k in bucket.keys :: lte(result, k)
      decreases this
    {
      MapSeqs.key_sets_eq(bucket.keys, bucket.msgs);
      MapSeqs.emptiness_map_of_seqs(bucket.keys, bucket.msgs);
      if format.BFTree? {
        result := LKMB.MinKey(format.tree);
      } else {
        assert format.BFPkv?;
        result := PackedKV.FirstKey(format.pkv);
        assert result == PackedKV.I(format.pkv).keys[0];
        reveal BucketsLib.Lexicographic_Byte_Order.IsSorted();
      }
    }
    method GetMiddleKey() returns (res: Key)
      requires Inv()
      ensures getMiddleKey(I()) == res
      decreases this
    {
      var pkv: PackedKV.Pkv;
      if format.BFPkv? {
        pkv := format.pkv;
      } else {
        NumElementsLteWeight(B(LKMB.Interpretation(format.tree)));
        pkv := tree_to_pkv(format.tree);
      }
      if |pkv.keys.offsets| as uint64 == 0 {
        return [0];
      } else {
        var key: Key := PackedKV.GetKey(pkv, |pkv.keys.offsets| as uint64 / 2);
        if |key| as uint64 == 0 {
          return [0];
        } else {
          return key;
        }
      }
    }
    method GetLastKey() returns (result: Key)
      requires Inv()
      requires BucketWellMarshalled(bucket)
      requires 0 < |bucket.keys|
      ensures result in bucket.keys
      ensures forall k: Element {:trigger lte(k, result)} {:trigger k in bucket.keys} | k in bucket.keys :: lte(k, result)
      decreases this
    {
      MapSeqs.key_sets_eq(bucket.keys, bucket.msgs);
      MapSeqs.emptiness_map_of_seqs(bucket.keys, bucket.msgs);
      if format.BFTree? {
        result := LKMB.MaxKey(format.tree);
      } else {
        assert format.BFPkv?;
        result := PackedKV.LastKey(format.pkv);
        assert result == Last(PackedKV.I(format.pkv).keys);
        reveal BucketsLib.Lexicographic_Byte_Order.IsSorted();
      }
    }
    method Insert(inout old_self: MutBucket, key: Key, value: Message)
        returns (self: MutBucket)
      requires old_self.Inv()
      requires old_self.weight as int + WeightKey(key) + WeightMessage(value) < 4294967296
      ensures self.Inv()
      ensures self.bucket == BucketInsert(old_self.bucket, key, value)
      decreases this, old_self, key, value
    {
      self := old_self;
      WFBucketInsert(self.bucket, key, value);
      if self.format.BFPkv? {
        var tree: TreeMap;
        var weight: uint64;
        tree, weight := pkv_to_tree(self.format.pkv);
        var _inout_tmp_0: uint64 := weight;
        self := self.(weight := _inout_tmp_0);
        var prevformat: BucketFormat, _inout_tmp_1: BucketFormat := Replace(inout self.format, BFTree(tree));
        self := self.(format := _inout_tmp_1);
        var _: () := FreeBucketFormat(prevformat);
        ghost var _inout_tmp_2: Bucket := B(self.bucket.as_map());
        self := self.(bucket := _inout_tmp_2);
        Weight_SortedBucket_le_UnsortedBucket(old_self.bucket, self.bucket);
      }
      ghost var old_bucket_map: map<Key, Value> := LKMB.Interpretation(self.format.tree);
      ghost var old_bucket: Bucket := self.bucket;
      Weight_BucketMap_eq_Bucket(self.bucket);
      assert old_bucket.as_map() == old_bucket_map;
      assert B(old_bucket_map) == old_bucket;
      assert old_bucket_map == old_self.bucket.as_map();
      if value.Define? {
        var MutBucket(format: BucketFormat, weight: uint64, sorted: bool, bucket: Bucket) := self;
        var BFTree(tree: TreeMap) := format;
        var cur: Option<Value>;
        tree, cur := LKMB.Insert(tree, key, value);
        if cur.Some? {
          ghost var map0: map<seq<NativeTypes.byte>, Value> := Maps.MapRemove1(old_bucket_map, key);
          WeightBucketInduct(map0, key, cur.value);
          WeightBucketInduct(map0, key, value);
          assert bucket.as_map()[key := value] == map0[key := value];
          assert bucket.as_map() == map0[key := cur.value];
          weight := weight - WeightMessageUint64(cur.value) + WeightMessageUint64(value) as uint64;
        } else {
          WeightBucketInduct(bucket.as_map(), key, value);
          weight := weight + WeightKeyUint64(key) + WeightMessageUint64(value);
        }
        self := MutBucket(BFTree(tree), weight, sorted, B(LKMB.Interpretation(tree)));
      }
      ghost var mergedMsg: Message := Merge(value, BucketMaps.BucketGet(old_bucket_map, key));
      assert mergedMsg == IdentityMessage() ==> LKMB.Interpretation(self.format.tree) == MapRemove1(old_self.bucket.as_map(), key) by {
        if key in old_bucket_map {
          ghost var j: int := MapSeqs.GetIndex(old_self.bucket.keys, old_self.bucket.msgs, key);
          assert old_bucket_map[key] != IdentityMessage();
        }
      }
      assert mergedMsg != IdentityMessage() ==> LKMB.Interpretation(self.format.tree) == old_self.bucket.as_map()[key := mergedMsg];
      Weight_BucketMap_eq_Bucket(self.bucket);
    }
    method Query(key: Key) returns (m: Option<Message>)
      requires Inv()
      ensures m == bucketBinarySearchLookup(I(), key)
      decreases this, key
    {
      if format.BFTree? {
        m := LKMB.Query(format.tree, key);
      } else if format.BFPkv? {
        m := PackedKV.BinarySearchQuery(format.pkv, key);
      }
    }
    method SplitLeft(pivot: Key) returns (left: MutBucket)
      requires Inv()
      ensures left.Inv()
      ensures left.bucket == SplitBucketLeft(bucket, pivot)
      decreases this, pivot
    {
      reveal_SplitBucketLeft();
      var pkv: PKV.Pkv := GetPkvSorted(false);
      var pkvleft: Pkv := PKV.SplitLeft(pkv, pivot);
      WeightSplitBucketLeft(PKV.I(pkv), pivot);
      WeightBucketPkv_eq_WeightPkv(pkvleft);
      assert sorted ==> BucketWellMarshalled(PackedKV.I(pkvleft)) by {
        reveal_SplitBucketLeft();
        Lexicographic_Byte_Order.reveal_IsStrictlySorted();
      }
      left := AllocPkv(pkvleft, sorted);
    }
    method SplitRight(pivot: Key) returns (right: MutBucket)
      requires Inv()
      ensures right.Inv()
      ensures right.bucket == SplitBucketRight(bucket, pivot)
      decreases this, pivot
    {
      var pkv: PKV.Pkv := GetPkvSorted(false);
      var pkvright: Pkv := PKV.SplitRight(pkv, pivot);
      WeightSplitBucketRight(PKV.I(pkv), pivot);
      WeightBucketPkv_eq_WeightPkv(pkvright);
      assert sorted ==> BucketWellMarshalled(PackedKV.I(pkvright)) by {
        reveal_SplitBucketRight();
        Lexicographic_Byte_Order.reveal_IsStrictlySorted();
      }
      right := AllocPkv(pkvright, sorted);
    }
    static method SplitLeftRight(b: MutBucket, pivot: Key)
        returns (left: MutBucket, right: MutBucket)
      requires b.Inv()
      ensures left.Inv()
      ensures right.Inv()
      ensures left.bucket == SplitBucketLeft(b.bucket, pivot)
      ensures right.bucket == SplitBucketRight(b.bucket, pivot)
      decreases b, pivot
    {
      left := b.SplitLeft(pivot);
      right := b.SplitRight(pivot);
    }
    static method SplitOneInList(inout old_buckets: lseq<MutBucket>, slot: uint64, pivot: Key)
        returns (buckets: lseq<MutBucket>)
      requires InvLseq(old_buckets)
      requires 0 <= slot as int < operator'cardinality?lseq(old_buckets)
      requires operator'cardinality?lseq(old_buckets) < 18446744073709551615
      ensures InvLseq(buckets)
      ensures ILseq(buckets) == SplitBucketInList(ILseq(old_buckets), slot as int, pivot)
      decreases slot, pivot
    {
      buckets := old_buckets;
      var l: MutBucket, r: MutBucket := SplitLeftRight(lseq_peek(buckets, slot), pivot);
      var replaced: MutBucket;
      var _inout_tmp_0: lseq<MutBucket>;
      replaced, _inout_tmp_0 := Replace1With2Lseq_inout(inout buckets, l, r, slot);
      buckets := _inout_tmp_0;
      var _: () := FreeMutBucket(replaced);
      ghost var ghosty: bool := true;
      if ghosty {
        reveal_ISeq();
        reveal_SplitBucketInList();
        ISeq_replace1with2(lseqs(buckets), l, r, slot as int);
      }
    }
    static method computeWeightOfSeq(buckets: lseq<MutBucket>) returns (weight: uint64)
      requires InvLseq(buckets)
      requires WeightBucketList(ILseq(buckets)) < 18446744073709551616
      requires operator'cardinality?lseq(buckets) < 18446744073709551616
      ensures weight as int == WeightBucketList(ILseq(buckets))
    {
      reveal_WeightBucketList();
      ghost var bs: seq<Bucket> := ILseq(buckets);
      var w: uint64 := 0;
      var j: uint64 := 0;
      while j < lseq_length_raw(buckets)
        invariant 0 <= j as int <= operator'cardinality?lseq(buckets)
        invariant w as int == WeightBucketList(bs[0 .. j])
        decreases lseq_length_raw(buckets) as int - j as int
      {
        assert DropLast(bs[0 .. j + 1]) == bs[0 .. j];
        assert Last(bs[0 .. j + 1]) == lseq_peek(buckets, j).I();
        WeightBucketListSlice(bs, 0, j as int + 1);
        w := w + lseq_peek(buckets, j).weight;
        j := j + 1;
      }
      assert bs[0 .. operator'cardinality?lseq(buckets)] == bs;
      return w;
    }
    static lemma Islice(buckets: lseq<MutBucket>, a: int, b: int)
      requires 0 <= a <= b <= operator'cardinality?lseq(buckets)
      requires InvLseq(buckets)
      ensures forall i: int {:trigger lseqs(buckets)[a .. b][i]} | 0 <= i < |lseqs(buckets)[a .. b]| :: lseqs(buckets)[a .. b][i].Inv()
      ensures ISeq(lseqs(buckets)[a .. b]) == ILseq(buckets)[a .. b]
      decreases operator'cardinality?lseq(buckets)
    {
      if b == operator'cardinality?lseq(buckets) {
        if a == b {
        } else {
          Islice(ldroplast(buckets), a, b - 1);
        }
      } else {
        Islice(ldroplast(buckets), a, b);
      }
    }
    method Clone() returns (bucket': MutBucket)
      requires Inv()
      ensures bucket'.Inv()
      ensures this.bucket == bucket'.bucket
      decreases this
    {
      if format.BFPkv? {
        DPKV.WeightBucketPkv_eq_WeightPkv(format.pkv);
        bucket' := AllocPkv(format.pkv, sorted);
      } else {
        var pkv: PackedKV.Pkv;
        NumElementsLteWeight(B(LKMB.Interpretation(format.tree)));
        pkv := tree_to_pkv(format.tree);
        DPKV.WeightBucketPkv_eq_WeightPkv(pkv);
        bucket' := AllocPkv(pkv, true);
      }
    }
    static method CloneSeq(buckets: lseq<MutBucket>, start: uint64, end: uint64)
        returns (buckets': lseq<MutBucket>)
      requires InvLseq(buckets)
      requires 0 <= start as int <= end as int <= operator'cardinality?lseq(buckets)
      requires operator'cardinality?lseq(buckets) < 18446744073709551616
      ensures InvLseq(buckets')
      ensures operator'cardinality?lseq(buckets') == (end - start) as int
      ensures ILseq(buckets') == ILseq(buckets)[start .. end]
      decreases start, end
    {
      buckets' := lseq_alloc(end - start);
      var j: uint64 := start;
      while j < end
        invariant start <= j <= end
        invariant operator'cardinality?lseq(buckets') == (end - start) as int
        invariant forall i: int {:trigger lseq_has(buckets')[i]} | (j - start) as int <= i < operator'cardinality?lseq(buckets') :: !lseq_has(buckets')[i]
        invariant forall i: int {:trigger lseq_has(buckets')[i]} | 0 <= i < (j - start) as int :: lseq_has(buckets')[i]
        invariant forall i: int {:trigger lseqs(buckets')[i]} | 0 <= i < (j - start) as int :: lseqs(buckets')[i].Inv()
        invariant forall i: int {:trigger lseqs(buckets')[i]} | 0 <= i < (j - start) as int :: lseqs(buckets')[i].I() == lseqs(buckets)[i + start as int].I()
        decreases end as int - j as int
      {
        var newbucket: MutBucket := lseq_peek(buckets, j).Clone();
        buckets' := lseq_give(buckets', j - start, newbucket);
        j := j + 1;
      }
    }
  }
  datatype BucketIter = BucketIter(it: Iterator, pkv: PackedKV.Pkv, ghost bucket: Bucket) {
    predicate WFIter()
      decreases this
    {
      PackedKV.WF(pkv) &&
      bucket == PackedKV.I(pkv) &&
      BucketIteratorModel.WFIter(bucket, IIterator(it))
    }
    method Free()
      decreases this
    {
      var BucketIter(_: Iterator, _: PackedKV.Pkv, _: Bucket) := this;
    }
    static function method makeIter(ghost bucket: Bucket, idx: uint64): (it': Iterator)
      requires WFBucket(bucket)
      requires |bucket.keys| == |bucket.msgs|
      requires 0 <= idx as int <= |bucket.keys|
      ensures IIterator(it') == BucketIteratorModel.iterForIndex(bucket, idx as int)
      decreases bucket, idx
    {
      Iterator(if idx as int == |bucket.keys| then BucketIteratorModel.Done else BucketIteratorModel.Next(bucket.keys[idx], bucket.msgs[idx]), idx, |bucket.keys| - idx as int)
    }
    static method IterStart(bucket: MutBucket) returns (biter: BucketIter)
      requires bucket.Inv()
      ensures biter.WFIter()
      ensures biter.bucket == bucket.I()
      ensures IIterator(biter.it) == BucketIteratorModel.IterStart(biter.bucket)
      decreases bucket
    {
      BucketIteratorModel.reveal_IterStart();
      ghost var b: Bucket := bucket.I();
      var pkv: PKV.Pkv := bucket.GetPkv();
      var it: Iterator := makeIter(b, 0);
      biter := BucketIter(it, pkv, b);
    }
    static method IterFindFirstGte(bucket: MutBucket, key: Key) returns (biter: BucketIter)
      requires bucket.Inv()
      ensures biter.WFIter()
      ensures biter.bucket == bucket.I()
      ensures IIterator(biter.it) == BucketIteratorModel.IterFindFirstGte(biter.bucket, key)
      decreases bucket, key
    {
      BucketIteratorModel.reveal_IterFindFirstGte();
      ghost var b: Bucket := bucket.I();
      var pkv: PKV.Pkv := bucket.GetPkv();
      var i: uint64 := PSA.BinarySearchIndexOfFirstKeyGte(pkv.keys, key);
      var it: Iterator := makeIter(b, i);
      biter := BucketIter(it, pkv, b);
    }
    static method IterFindFirstGt(bucket: MutBucket, key: Key) returns (biter: BucketIter)
      requires bucket.Inv()
      ensures biter.WFIter()
      ensures biter.bucket == bucket.I()
      ensures IIterator(biter.it) == BucketIteratorModel.IterFindFirstGt(biter.bucket, key)
      decreases bucket, key
    {
      BucketIteratorModel.reveal_IterFindFirstGt();
      ghost var b: Bucket := bucket.I();
      var pkv: PKV.Pkv := bucket.GetPkv();
      var i: uint64 := PSA.BinarySearchIndexOfFirstKeyGt(pkv.keys, key);
      var it: Iterator := makeIter(b, i);
      biter := BucketIter(it, pkv, b);
    }
    method IterInc(inout old_self: BucketIter) returns (self: BucketIter)
      requires old_self.WFIter()
      requires IIterator(old_self.it).next.Next?
      ensures self.WFIter()
      ensures old_self.bucket == self.bucket
      ensures IIterator(self.it) == BucketIteratorModel.IterInc(old_self.bucket, IIterator(old_self.it))
      decreases this, old_self
    {
      self := old_self;
      BucketIteratorModel.lemma_NextFromIndex(self.bucket, IIterator(self.it));
      BucketIteratorModel.reveal_IterInc();
      NumElementsLteWeight(self.bucket);
      var _inout_tmp_0: Iterator := makeIter(self.bucket, self.it.i + 1);
      self := self.(it := _inout_tmp_0);
    }
    method GetNext() returns (next: BucketIteratorModel.IteratorOutput)
      requires this.WFIter()
      ensures next == IIterator(this.it).next
      decreases this
    {
      BucketIteratorModel.lemma_NextFromIndex(bucket, IIterator(it));
      if it.i == |pkv.keys.offsets| as uint64 {
        next := BucketIteratorModel.Done;
      } else {
        next := BucketIteratorModel.Next(PackedKV.GetKey(pkv, it.i), PackedKV.GetMessage(pkv, it.i));
      }
    }
  }
  method pkv_to_tree(pkv: PackedKV.Pkv) returns (tree: TreeMap, weight: uint64)
    requires PackedKV.WF(pkv)
    ensures LKMB.WF(tree)
    ensures LKMBPKVOps.IsKeyMessageTree(tree)
    ensures PackedKV.I(pkv).as_map() == LKMB.Interpretation(tree)
    ensures weight as nat == BucketWeights.WeightBucket(BucketsLib.B(LKMB.Interpretation(tree)))
    decreases pkv
  {
    tree, weight := LKMBPKVOps.FromPkv(pkv);
  }
  method tree_to_pkv(tree: TreeMap) returns (pkv: PackedKV.Pkv)
    requires LKMB.WF(tree)
    requires LKMBPKVOps.IsKeyMessageTree(tree)
    requires BucketWeights.WeightBucket(BucketsLib.B(LKMB.Interpretation(tree))) < Uint32UpperBound()
    ensures PackedKV.WF(pkv)
    ensures PackedKV.I(pkv) == B(LKMB.Interpretation(tree))
    decreases tree
  {
    LKMBPKVOps.WeightImpliesCanAppend(tree);
    pkv := LKMBPKVOps.ToPkv(tree);
  }
  function IIterator(it: Iterator): BucketIteratorModel.Iterator
    decreases it
  {
    BucketIteratorModel.Iterator(it.next, it.i as int, it.decreaser)
  }
  function method FreeBucketFormat(format: BucketFormat): ()
    requires format.BFTree? ==> LKMB.WF(format.tree)
    decreases format
  {
    match format {
      case BFTree(tree) =>
        var _ := LKMB.FreeNode(tree);
        ()
      case BFPkv(_v1) =>
        ()
    }
  }
  function method FreeMutBucket(bucket: MutBucket): ()
    requires bucket.Inv()
    decreases bucket
  {
    var MutBucket(format: BucketFormat, _: uint64, _: bool, _: Bucket) := bucket;
    var _: () := FreeBucketFormat(format);
    ()
  }
  function method FreeMutBucketSeqRecur(buckets: lseq<MutBucket>, i: uint64): (ebuckets: lseq<MutBucket>)
    requires operator'cardinality?lseq(buckets) < Uint64UpperBound()
    requires 0 <= i as nat < operator'cardinality?lseq(buckets)
    requires MutBucket.InvSeq(lseqs(buckets)[i..])
    requires forall j: int {:trigger operator'in?lseq(buckets, j)} | i as nat <= j < operator'cardinality?lseq(buckets) :: operator'in?lseq(buckets, j)
    ensures operator'cardinality?lseq(ebuckets) == operator'cardinality?lseq(buckets)
    ensures forall j: int {:trigger operator'in?lseq(ebuckets, j)} {:trigger operator'in?lseq(buckets, j)} | 0 <= j < operator'cardinality?lseq(buckets) :: !operator'in?lseq(buckets, j) ==> !operator'in?lseq(ebuckets, j)
    ensures forall j: int {:trigger operator'in?lseq(ebuckets, j)} | i as nat <= j < operator'cardinality?lseq(ebuckets) :: !operator'in?lseq(ebuckets, j)
    decreases operator'cardinality?lseq(buckets) as uint64 - i
  {
    var (buckets': lseq<MutBucket>, wastebucket: MutBucket) := lseq_take_fun(buckets, i);
    var _: () := FreeMutBucket(wastebucket);
    if i + 1 == lseq_length_as_uint64(buckets') then
      buckets'
    else
      var e: lseq<MutBucket> := FreeMutBucketSeqRecur(buckets', i + 1); e
  }
  function method FreeMutBucketSeq(buckets: lseq<MutBucket>): ()
    requires operator'cardinality?lseq(buckets) < Uint64UpperBound()
    requires MutBucket.InvLseq(buckets)
  {
    if lseq_length_as_uint64(buckets) == 0 then
      lseq_free_fun(buckets)
    else
      var buckets': lseq<MutBucket> := FreeMutBucketSeqRecur(buckets, 0); lseq_free_fun(buckets')
  }
  method pkvList2BucketList(pkvs: seq<PKV.Pkv>, sorted: bool) returns (buckets: lseq<MutBucket>)
    requires |pkvs| < Uint64UpperBound()
    requires forall i: int {:trigger pkvs[i]} | 0 <= i < |pkvs| :: WF(pkvs[i])
    requires forall i: int {:trigger pkvs[i]} | 0 <= i < |pkvs| :: PackedKV.WeightPkv(pkvs[i]) as nat < Uint32UpperBound()
    requires sorted ==> forall i: int {:trigger pkvs[i]} | 0 <= i < |pkvs| :: BucketWellMarshalled(PKV.I(pkvs[i]))
    ensures operator'cardinality?lseq(buckets) == |pkvs|
    ensures MutBucket.InvLseq(buckets)
    ensures MutBucket.ILseq(buckets) == DPKV.PKVISeq(pkvs)
    decreases pkvs, sorted
  {
    buckets := lseq_alloc(|pkvs| as uint64);
    var i: uint64 := 0;
    while i < |pkvs| as uint64
      invariant i as nat <= |pkvs|
      invariant |pkvs| == operator'cardinality?lseq(buckets)
      invariant forall j: int {:trigger lseq_has(buckets)[j]} | i as int <= j < operator'cardinality?lseq(buckets) :: !lseq_has(buckets)[j]
      invariant forall j: int {:trigger lseq_has(buckets)[j]} | 0 <= j < i as int :: lseq_has(buckets)[j]
      invariant forall j: uint64 {:trigger lseqs(buckets)[j]} | 0 <= j < i :: lseqs(buckets)[j].Inv()
      invariant forall j: uint64 {:trigger pkvs[j]} {:trigger lseqs(buckets)[j]} | 0 <= j < i :: lseqs(buckets)[j].bucket == PKV.I(pkvs[j])
      decreases |pkvs| as uint64 as int - i as int
    {
      var newbucket: MutBucket := MutBucket.AllocPkv(pkvs[i], sorted);
      buckets := lseq_give(buckets, i, newbucket);
      i := i + 1;
    }
  }
  method PartialFlush(top: MutBucket, bots: lseq<MutBucket>, pivots: Pivots.PivotTable)
      returns (newtop: MutBucket, newbots: lseq<MutBucket>)
    requires top.Inv()
    requires MutBucket.InvLseq(bots)
    requires Pivots.WFPivots(pivots)
    requires |pivots| < Uint64UpperBound()
    requires Pivots.NumBuckets(pivots) == operator'cardinality?lseq(bots)
    requires WeightBucket(top.I()) <= MaxTotalBucketWeight()
    requires WeightBucketList(MutBucket.ILseq(bots)) <= MaxTotalBucketWeight()
    ensures MutBucket.InvLseq(newbots)
    ensures newtop.Inv()
    ensures partialFlushResult(newtop.I(), MutBucket.ILseq(newbots)) == BucketFlushModel.partialFlush(top.I(), pivots, MutBucket.ILseq(bots))
    decreases top, pivots
  {
    var i: uint64 := 0;
    var bots_len: uint64 := lseq_length_raw(bots);
    var botPkvs: array<PKV.Pkv> := new PKV.Pkv[bots_len];
    var sorted: bool := true;
    while i < bots_len
      invariant i as nat <= operator'cardinality?lseq(bots)
      invariant forall j: uint64 {:trigger botPkvs[j]} | 0 <= j < i :: WF(botPkvs[j])
      invariant forall j: uint64 {:trigger lseqs(bots)[j]} {:trigger botPkvs[j]} | 0 <= j < i :: PKV.I(botPkvs[j]) == lseqs(bots)[j].bucket
      invariant forall j: uint64 {:trigger botPkvs[j]} | 0 <= j < i :: |PKV.IKeys(botPkvs[j].keys)| < 268435456
      invariant sorted ==> forall j: uint64 {:trigger botPkvs[j]} | 0 <= j < i :: BucketWellMarshalled(PKV.I(botPkvs[j]))
      decreases bots_len as int - i as int
    {
      botPkvs[i] := lseq_peek(bots, i).GetPkv();
      NumElementsLteWeight(PKV.I(botPkvs[i]));
      WeightBucketLeBucketList(MutBucket.ILseq(bots), i as int);
      if !lseq_peek(bots, i).sorted {
        sorted := false;
      }
      i := i + 1;
    }
    var botPkvsSeq: seq<PKV.Pkv> := botPkvs[..];
    NumElementsLteWeight(top.bucket);
    assert DPKV.PKVISeq(botPkvsSeq) == MutBucket.ILseq(bots);
    var topPkv: PKV.Pkv := top.GetPkv();
    if !top.sorted {
      sorted := false;
    }
    var result: PartialFlushResult := DPKV.PartialFlush(topPkv, pivots, botPkvsSeq);
    assert sorted ==> BucketWellMarshalled(PKV.I(result.top)) && forall j: int {:trigger result.bots[j]} | 0 <= j < |result.bots| :: BucketWellMarshalled(PKV.I(result.bots[j])) by {
      if sorted {
        partialFlushPreservesSorted(top.bucket, pivots, MutBucket.ILseq(bots));
      }
    }
    partialFlushWeightBound(top.I(), pivots, MutBucket.ILseq(bots));
    DPKV.WeightBucketPkv_eq_WeightPkv(result.top);
    forall i: int {:trigger result.bots[i]} | 0 <= i < |result.bots|
      ensures PackedKV.WeightPkv(result.bots[i]) as nat < Uint32UpperBound()
    {
      WeightBucketLeBucketList(DPKV.PKVISeq(result.bots), i);
      DPKV.WeightBucketPkv_eq_WeightPkv(result.bots[i]);
    }
    newtop := MutBucket.AllocPkv(result.top, sorted);
    newbots := pkvList2BucketList(result.bots, sorted);
  }
}
Dafny program verifier did not attempt verification