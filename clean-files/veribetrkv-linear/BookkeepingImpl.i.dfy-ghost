// BookkeepingImpl.i.dfy
module BookkeepingImpl {
  predicate RefAvailable(s: ImplVariables, ref: BT.G.Reference)
    requires s.Ready? && s.W()
    decreases s, ref
  {
    ref !in s.ephemeralIndirectionTable.I().graph &&
    ref !in s.cache.I() &&
    ref != BT.G.Root()
  }
  method getFreeRef(s: ImplVariables) returns (ref: Option<BT.G.Reference>)
    requires s.Ready?
    requires s.W()
    ensures s.Ready?
    ensures s.W()
    ensures ref.Some? ==> RefAvailable(s, ref.value)
    ensures forall ref1: NativeTypes.uint64 {:trigger Some(ref1)} {:trigger ref1 in s.cache.I()} | ref1 in s.cache.I() :: Some(ref1) != ref
    ensures (forall r: uint64 {:trigger r in s.ephemeralIndirectionTable.graph} | r in s.ephemeralIndirectionTable.graph :: r <= s.ephemeralIndirectionTable.refUpperBound) && ref == BookkeepingModel.getFreeRef(s.I(), s.ephemeralIndirectionTable.refUpperBound)
    decreases s
  {
    BookkeepingModel.reveal_getFreeRef();
    ghost var getable: IndirectionTable := s.I().ephemeralIndirectionTable;
    s.ephemeralIndirectionTable.UpperBounded();
    var upperBound: uint64 := s.ephemeralIndirectionTable.refUpperBound;
    var i: uint64 := upperBound;
    if i == 18446744073709551615 {
      return None;
    }
    i := i + 1;
    while true
      invariant i >= 1
      invariant forall r: uint64 {:trigger r in s.ephemeralIndirectionTable.graph} | r in s.ephemeralIndirectionTable.graph :: r < i
      invariant BookkeepingModel.getFreeRefIterate(s.I(), i) == BookkeepingModel.getFreeRef(s.I(), upperBound)
      decreases 18446744073709551616 - i as int
    {
      var cacheLookup: bool := s.cache.InCache(i);
      if !cacheLookup {
        return Some(i);
      }
      if i == 18446744073709551615 {
        return None;
      } else {
        i := i + 1;
      }
    }
  }
  method getFreeRef2(s: ImplVariables, avoid: BT.G.Reference) returns (ref: Option<BT.G.Reference>)
    requires s.Ready?
    requires s.W()
    ensures ref.Some? ==> ref.value != avoid
    ensures ref.Some? ==> RefAvailable(s, ref.value)
    ensures forall ref1: NativeTypes.uint64 {:trigger Some(ref1)} {:trigger ref1 in s.cache.I()} | ref1 in s.cache.I() :: Some(ref1) != ref
    ensures (forall r: uint64 {:trigger r in s.ephemeralIndirectionTable.graph} | r in s.ephemeralIndirectionTable.graph :: r <= s.ephemeralIndirectionTable.refUpperBound) && ref == BookkeepingModel.getFreeRef2(s.I(), avoid, s.ephemeralIndirectionTable.refUpperBound)
    decreases s, avoid
  {
    BookkeepingModel.reveal_getFreeRef2();
    s.ephemeralIndirectionTable.UpperBounded();
    var upperBound: uint64 := s.ephemeralIndirectionTable.refUpperBound;
    var i: uint64 := upperBound;
    if i == 18446744073709551615 {
      return None;
    }
    i := i + 1;
    while true
      invariant i >= 1
      invariant forall r: uint64 {:trigger r in s.ephemeralIndirectionTable.I().graph} | r in s.ephemeralIndirectionTable.I().graph :: r < i
      invariant BookkeepingModel.getFreeRef2Iterate(s.I(), avoid, i) == BookkeepingModel.getFreeRef2(s.I(), avoid, upperBound)
      decreases 18446744073709551616 - i as int
    {
      if i != avoid {
        var cacheLookup: bool := s.cache.InCache(i);
        if !cacheLookup {
          return Some(i);
        }
      }
      if i == 18446744073709551615 {
        return None;
      } else {
        i := i + 1;
      }
    }
  }
  lemma lemmaIndirectionTableLocIndexValid(s: ImplVariables, ref: BT.G.Reference)
    requires s.W()
    requires s.WriteAllocConditions()
    ensures ref in s.ephemeralIndirectionTable.locs ==> 0 <= s.ephemeralIndirectionTable.locs[ref].addr as int / NodeBlockSize() < NumBlocks() && s.ephemeralIndirectionTable.locs[ref].addr as int / NodeBlockSize() * NodeBlockSize() == s.ephemeralIndirectionTable.locs[ref].addr as int
    decreases s, ref
  {
    if ref in s.ephemeralIndirectionTable.locs {
      reveal_ConsistentBitmapInteral();
      ghost var loc: Location := s.ephemeralIndirectionTable.locs[ref];
      ghost var i: int := loc.addr as int / NodeBlockSize();
      assert s.ephemeralIndirectionTable.I().locs[ref] == loc;
      assert loc in s.ephemeralIndirectionTable.I().locs.Values;
      assert DiskLayout.ValidNodeLocation(loc);
      DiskLayout.reveal_ValidNodeAddr();
      assert i * NodeBlockSize() == loc.addr as int;
      assert IT.IndirectionTable.IsLocAllocBitmap(s.blockAllocator.I().ephemeral, i);
    }
  }
  lemma freeIndirectionTableLocCorrect(s: ImplVariables, s': ImplVariables, ref: BT.G.Reference, j: Option<int>)
    requires s.WriteAllocConditions()
    requires s.W()
    requires s'.W()
    requires s'.Ready?
    requires forall r: NativeTypes.uint64 {:trigger MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r)} | r != ref :: MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r)
    requires ref !in s'.ephemeralIndirectionTable.I().locs
    requires j.Some? ==> 0 <= j.value < NumBlocks()
    requires j.Some? ==> ref in s.ephemeralIndirectionTable.I().locs
    requires j.Some? ==> s.ephemeralIndirectionTable.I().locs[ref].addr as int == j.value * NodeBlockSize()
    requires j.Some? ==> s'.blockAllocator.I() == BlockAllocatorModel.MarkFreeEphemeral(s.blockAllocator.I(), j.value)
    requires j.None? ==> s'.blockAllocator == s.blockAllocator
    requires j.None? ==> ref !in s.ephemeralIndirectionTable.I().locs
    ensures forall i: int {:trigger IT.IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i)} {:trigger s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i)} :: s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i) <==> IT.IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i)
    ensures BlockAllocatorModel.Inv(s'.blockAllocator.I())
    ensures BC.AllLocationsForDifferentRefsDontOverlap(s'.ephemeralIndirectionTable.I())
    ensures forall loc: Location {:trigger ValidNodeLocation(loc)} {:trigger loc in s'.ephemeralIndirectionTable.I().locs.Values} | loc in s'.ephemeralIndirectionTable.I().locs.Values :: ValidNodeLocation(loc)
    decreases s, s', ref, j
  {
    reveal_ConsistentBitmapInteral();
    BitmapModel.reveal_IsSet();
    BitmapModel.reveal_BitUnset();
    lemmaIndirectionTableLocIndexValid(s, ref);
    forall r1: NativeTypes.uint64, r2: NativeTypes.uint64 {:trigger LocationsForDifferentRefsDontOverlap(s'.ephemeralIndirectionTable.I(), r1, r2)} {:trigger r2 in s'.ephemeralIndirectionTable.I().locs, r1 in s'.ephemeralIndirectionTable.I().locs} | r1 in s'.ephemeralIndirectionTable.I().locs && r2 in s'.ephemeralIndirectionTable.I().locs
      ensures LocationsForDifferentRefsDontOverlap(s'.ephemeralIndirectionTable.I(), r1, r2)
    {
      assert MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r1);
      assert MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r2);
    }
    forall loc: Location {:trigger ValidNodeLocation(loc)} {:trigger loc in s'.ephemeralIndirectionTable.I().locs.Values} | loc in s'.ephemeralIndirectionTable.I().locs.Values
      ensures ValidNodeLocation(loc)
    {
      ghost var r: NativeTypes.uint64 :| r in s'.ephemeralIndirectionTable.I().locs && s'.ephemeralIndirectionTable.I().locs[r] == loc;
      assert MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r);
    }
    if j.Some? {
      assert DiskLayout.ValidNodeLocation(s.ephemeralIndirectionTable.I().locs[ref]);
      assert j.value >= MinNodeBlockIndex() by {
        DiskLayout.reveal_ValidNodeAddr();
      }
    }
    forall i: int {:trigger IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i)} {:trigger s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i)} | s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i)
      ensures IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i)
    {
      if j.Some? && i == j.value {
        if 0 <= i < MinNodeBlockIndex() {
          assert false;
        } else {
          ghost var r: NativeTypes.uint64 :| r in s'.ephemeralIndirectionTable.locs && s'.ephemeralIndirectionTable.locs[r].addr as int == i * NodeBlockSize() as int;
          assert MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r);
          assert BC.LocationsForDifferentRefsDontOverlap(s.ephemeralIndirectionTable.I(), ref, r);
          assert ref !in s'.ephemeralIndirectionTable.I().locs;
          assert r in s'.ephemeralIndirectionTable.I().locs;
          assert s.ephemeralIndirectionTable.I().locs[r] == s.ephemeralIndirectionTable.I().locs[ref];
          assert r == ref;
          assert false;
        }
      } else {
        if 0 <= i < MinNodeBlockIndex() {
          assert s.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i);
          assert IT.IndirectionTable.IsLocAllocBitmap(s.blockAllocator.I().ephemeral, i);
          assert IT.IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i);
        } else {
          ghost var r: NativeTypes.uint64 :| r in s'.ephemeralIndirectionTable.locs && s'.ephemeralIndirectionTable.locs[r].addr as int == i * NodeBlockSize() as int;
          assert MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r);
          assert s.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i);
          assert IT.IndirectionTable.IsLocAllocBitmap(s.blockAllocator.I().ephemeral, i);
          assert IT.IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i);
        }
      }
    }
    forall i: int {:trigger s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i)} {:trigger IT.IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i)} | IT.IndirectionTable.IsLocAllocBitmap(s'.blockAllocator.I().ephemeral, i)
      ensures s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i)
    {
      if j.Some? && i == j.value {
        assert s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i);
      } else {
        assert IT.IndirectionTable.IsLocAllocBitmap(s.blockAllocator.I().ephemeral, i);
        assert s.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i);
        if 0 <= i < MinNodeBlockIndex() {
          assert s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i);
        } else {
          ghost var r: NativeTypes.uint64 :| r in s.ephemeralIndirectionTable.locs && s.ephemeralIndirectionTable.locs[r].addr as int == i * NodeBlockSize() as int;
          assert MapsAgreeOnKey(s.ephemeralIndirectionTable.I().locs, s'.ephemeralIndirectionTable.I().locs, r);
          assert r in s'.ephemeralIndirectionTable.locs && s'.ephemeralIndirectionTable.locs[r].addr as int == i * NodeBlockSize() as int;
          assert s'.ephemeralIndirectionTable.I().IsLocAllocIndirectionTable(i);
        }
      }
    }
    if j.Some? {
      forall i: int {:trigger BitmapModel.IsSet(s'.blockAllocator.I().persistent, i)} {:trigger BitmapModel.IsSet(s'.blockAllocator.I().frozen.value, i)} {:trigger BitmapModel.IsSet(s'.blockAllocator.I().ephemeral, i)} {:trigger BitmapModel.IsSet(s'.blockAllocator.I().full, i)} | 0 <= i < NumBlocks()
        ensures BitmapModel.IsSet(s'.blockAllocator.I().full, i) == (BitmapModel.IsSet(s'.blockAllocator.I().ephemeral, i) || (s'.blockAllocator.I().frozen.Some? && BitmapModel.IsSet(s'.blockAllocator.I().frozen.value, i)) || BitmapModel.IsSet(s'.blockAllocator.I().persistent, i) || BitmapModel.IsSet(s'.blockAllocator.I().full, i))
      {
        if i == j.value {
        } else {
          assert BitmapModel.IsSet(s'.blockAllocator.I().full, i) == BitmapModel.IsSet(s.blockAllocator.I().full, i);
          assert BitmapModel.IsSet(s'.blockAllocator.I().ephemeral, i) == BitmapModel.IsSet(s.blockAllocator.I().ephemeral, i);
          assert s'.blockAllocator.I().frozen.Some? ==> BitmapModel.IsSet(s'.blockAllocator.I().frozen.value, i) == BitmapModel.IsSet(s.blockAllocator.I().frozen.value, i);
          assert BitmapModel.IsSet(s'.blockAllocator.I().persistent, i) == BitmapModel.IsSet(s.blockAllocator.I().persistent, i);
          assert BitmapModel.IsSet(s'.blockAllocator.I().outstanding, i) == BitmapModel.IsSet(s.blockAllocator.I().outstanding, i);
        }
      }
    }
  }
  method writeBookkeeping(inout old_s: ImplVariables, ref: BT.G.Reference, children: Option<seq<BT.G.Reference>>)
      returns (s: ImplVariables)
    requires old_s.W()
    requires old_s.Ready?
    requires |LruModel.I(old_s.lru.Queue())| <= 4294967296
    requires old_s.WriteAllocConditions()
    requires old_s.ChildrenConditions(children)
    requires |old_s.ephemeralIndirectionTable.I().graph| < IndirectionTable.MaxSize()
    ensures s.W()
    ensures s.Ready?
    ensures |LruModel.I(s.lru.Queue())| <= |LruModel.I(old_s.lru.Queue())| + 1
    ensures s.WriteAllocConditions()
    ensures s.ChildrenConditions(Some([ref]))
    ensures s.I() == BookkeepingModel.writeBookkeeping(old_s.I(), ref, children)
    ensures s.cache == old_s.cache
    ensures LruModel.I(s.lru.Queue()) == LruModel.I(old_s.lru.Queue()) + {ref}
    decreases old_s, ref, children
  {
    s := old_s;
    lemmaIndirectionTableLocIndexValid(s, ref);
    var oldLoc: Option<Location>, _inout_tmp_1: IndirectionTable := s.ephemeralIndirectionTable.UpdateAndRemoveLoc(inout s.ephemeralIndirectionTable, ref, if children.Some? then children.value else []);
    s := s.(ephemeralIndirectionTable := _inout_tmp_1);
    var _inout_tmp_2: LinearLru;
    _inout_tmp_2 := s.lru.Use(inout s.lru, ref);
    s := s.(lru := _inout_tmp_2);
    if oldLoc.Some? {
      var _inout_tmp_0: BlockAllocator;
      _inout_tmp_0 := s.blockAllocator.MarkFreeEphemeral(inout s.blockAllocator, oldLoc.value.addr / NodeBlockSizeUint64());
      s := s.(blockAllocator := _inout_tmp_0);
    }
    LruModel.LruUse(old_s.lru.Queue(), ref);
    assert LruModel.I(s.lru.Queue()) == LruModel.I(old_s.lru.Queue()) + {ref};
    assert |LruModel.I(s.lru.Queue())| == |LruModel.I(old_s.lru.Queue()) + {ref}| <= |LruModel.I(old_s.lru.Queue())| + |{ref}| == |LruModel.I(old_s.lru.Queue())| + 1;
    reveal BookkeepingModel.writeBookkeeping();
    freeIndirectionTableLocCorrect(old_s, s, ref, if oldLoc.Some? then Some(oldLoc.value.addr as int / NodeBlockSize()) else None);
    reveal_ConsistentBitmapInteral();
    assert s.WriteAllocConditions();
  }
  method allocBookkeeping(inout old_s: ImplVariables, children: Option<seq<BT.G.Reference>>)
      returns (ref: Option<BT.G.Reference>, s: ImplVariables)
    requires old_s.W()
    requires old_s.Ready?
    requires |LruModel.I(old_s.lru.Queue())| <= 4294967296
    requires old_s.WriteAllocConditions()
    requires old_s.ChildrenConditions(children)
    requires |old_s.ephemeralIndirectionTable.I().graph| < IndirectionTable.MaxSize()
    ensures s.Ready?
    ensures s.W()
    ensures |LruModel.I(s.lru.Queue())| <= |LruModel.I(old_s.lru.Queue())| + 1
    ensures s.cache.I() == old_s.cache.I()
    ensures ref.Some? ==> s.ChildrenConditions(Some([ref.value]))
    ensures s.WriteAllocConditions()
    ensures forall r: uint64 {:trigger r in old_s.ephemeralIndirectionTable.graph} | r in old_s.ephemeralIndirectionTable.graph :: r <= old_s.ephemeralIndirectionTable.refUpperBound
    ensures (s.I(), ref) == BookkeepingModel.allocBookkeeping(old_s.I(), children, old_s.ephemeralIndirectionTable.refUpperBound)
    ensures ref.None? ==> s == old_s
    ensures ref.Some? ==> LruModel.I(s.lru.Queue()) == LruModel.I(old_s.lru.Queue()) + {ref.value}
    decreases old_s, children
  {
    s := old_s;
    BookkeepingModel.reveal_allocBookkeeping();
    ref := getFreeRef(s);
    if ref.Some? {
      var _inout_tmp_0: ImplVariables;
      _inout_tmp_0 := writeBookkeeping(inout s, ref.value, children);
      s := _inout_tmp_0;
    }
  }
  method writeBookkeepingNoSuccsUpdate(inout old_s: ImplVariables, ref: BT.G.Reference) returns (s: ImplVariables)
    requires old_s.W()
    requires old_s.Ready?
    requires |LruModel.I(old_s.lru.Queue())| <= 4294967296
    requires old_s.WriteAllocConditions()
    requires ref in old_s.ephemeralIndirectionTable.I().graph
    ensures s.W()
    ensures s.WriteAllocConditions()
    ensures s.I() == BookkeepingModel.writeBookkeepingNoSuccsUpdate(old_s.I(), ref)
    ensures |LruModel.I(s.lru.Queue())| <= |LruModel.I(old_s.lru.Queue())| + 1
    ensures LruModel.I(s.lru.Queue()) == LruModel.I(old_s.lru.Queue()) + {ref}
    decreases old_s, ref
  {
    s := old_s;
    BookkeepingModel.reveal_writeBookkeepingNoSuccsUpdate();
    lemmaIndirectionTableLocIndexValid(s, ref);
    var oldLoc: Option<Location>, _inout_tmp_1: IndirectionTable := s.ephemeralIndirectionTable.RemoveLoc(inout s.ephemeralIndirectionTable, ref);
    s := s.(ephemeralIndirectionTable := _inout_tmp_1);
    var _inout_tmp_2: LinearLru;
    _inout_tmp_2 := s.lru.Use(inout s.lru, ref);
    s := s.(lru := _inout_tmp_2);
    if oldLoc.Some? {
      var _inout_tmp_0: BlockAllocator;
      _inout_tmp_0 := s.blockAllocator.MarkFreeEphemeral(inout s.blockAllocator, oldLoc.value.addr / NodeBlockSizeUint64());
      s := s.(blockAllocator := _inout_tmp_0);
    }
    freeIndirectionTableLocCorrect(old_s, s, ref, if oldLoc.Some? then Some(oldLoc.value.addr as int / NodeBlockSize()) else None);
    reveal ConsistentBitmapInteral();
    LruModel.LruUse(old_s.lru.Queue(), ref);
    assert LruModel.I(s.lru.Queue()) == LruModel.I(old_s.lru.Queue()) + {ref};
    assert |LruModel.I(s.lru.Queue())| == |LruModel.I(old_s.lru.Queue()) + {ref}| <= |LruModel.I(old_s.lru.Queue())| + |{ref}| == |LruModel.I(old_s.lru.Queue())| + 1;
  }
}
Dafny program verifier did not attempt verification