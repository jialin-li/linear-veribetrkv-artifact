// CacheImpl.i.dfy
module CacheImpl {
    reveals LMutCache, LMutCache.Inv, LMutCache.ptr, LMutCache.I, CacheCount
    reveals LMutCache, LMutCache.Inv, LMutCache.ptr, LMutCache.I, CacheCount
  datatype   LMutCache = LMutCache(cache: LinearHashMap<Node>) {
    static method DebugAccumulate(c: LMutCache) returns (acc: DebugAccumulator.DebugAccumulator)
      requires false
      decreases c
    {
      acc := DebugAccumulator.EmptyAccumulator();
      var a: DebugAccumulator.AccRec := new DebugAccumulator.AccRec(c.cache.count, "Node");
      acc := DebugAccumulator.AccPut(acc, "cache", a);
    }
    static method NewCache() returns (newcache: LMutCache)
      ensures newcache.Inv()
      ensures newcache.I() == map[]
    {
      var cache: LinearHashMap<Node> := LCMM.Constructor(128);
      newcache := LMutCache(cache);
    }
    predicate Inv()
      decreases this
    {
      LCMM.Inv(cache) &&
      forall ref: uint64 {:trigger cache.contents[ref]} {:trigger ref in cache.contents} | ref in cache.contents :: 
        cache.contents[ref].Inv()
    }
    function I(): map<BT.G.Reference, BT.G.Node>
      requires Inv()
      decreases this
    {
      map ref: uint64 {:trigger cache.contents[ref]} {:trigger ref in cache.contents} | ref in cache.contents :: cache.contents[ref].I()
    }
    function ptr(ref: BT.G.Reference): Option<Node>
      requires Inv()
      ensures ptr(ref).None? ==> ref !in I()
      ensures ptr(ref).Some? ==> ref in I() && ptr(ref).value.Inv() && I()[ref] == ptr(ref).value.I()
      decreases this, ref
    {
      if ref in cache.contents then
        Some(cache.contents[ref])
      else
        None
    }
    method InCache(ref: BT.G.Reference) returns (b: bool)
      requires Inv()
      ensures b == ptr(ref).Some?
      decreases this, ref
    {
      b := IsEntry(cache.underlying, ref);
    }
    method Get(ref: BT.G.Reference) returns (node: Node)
      requires Inv()
      requires ptr(ref).Some?
      ensures node == ptr(ref).value
      decreases this, ref
    {
      node := LCMM.Get(cache, ref);
    }
    lemma  LemmaSizeEqCount()
      requires Inv()
      ensures |I()| == |cache.contents|
      decreases this
    {
      assert I().Keys == cache.contents.Keys;
      assert |I()| == |I().Keys| == |cache.contents.Keys| == |cache.contents|;
    }
    method Insert(inout old_self: LMutCache, ref: BT.G.Reference, node: Node)
        returns (self: LMutCache)
      requires old_self.Inv()
      requires node.Inv()
      requires |old_self.I()| <= 65536
      ensures self.Inv()
      ensures self.I() == old_self.I()[ref := node.I()]
      ensures forall r: NativeTypes.uint64 {:trigger old_self.ptr(r)} {:trigger self.ptr(r)} | r != ref :: self.ptr(r) == old_self.ptr(r)
      decreases this, old_self, ref, node
    {
      self := old_self;
      self.LemmaSizeEqCount();
      var replaced: lOption<Node>, _inout_tmp_0: LinearHashMap<Node> := LCMM.Insert(inout self.cache, ref, node);
      self := self.(cache := _inout_tmp_0);
      match replaced {
        case lSome(oldnode) =>
          {
            var _ := FreeNode(oldnode);
          }
        case lNone() =>
          {
          }
      }
      assert self.cache.contents[ref] == node;
      assert self.Inv();
    }
    method ReplaceAndGet(inout old_self: LMutCache, ref: BT.G.Reference, newNode: Node)
        returns (oldNode: Node, self: LMutCache)
      requires old_self.Inv()
      requires old_self.ptr(ref).Some?
      requires |old_self.I()| <= 65536
      requires newNode.Inv()
      ensures self.Inv()
      ensures oldNode.Inv()
      ensures |self.I()| == |old_self.I()|
      ensures oldNode == old_self.ptr(ref).value
      ensures self.I() == old_self.I()[ref := newNode.I()]
      ensures forall r: NativeTypes.uint64 {:trigger old_self.ptr(r)} {:trigger self.ptr(r)} | r != ref :: self.ptr(r) == old_self.ptr(r)
      decreases this, old_self, ref, newNode
    {
      self := old_self;
      self.LemmaSizeEqCount();
      var replaced: lOption<Node>, _inout_tmp_0: LinearHashMap<Node> := LCMM.Insert(inout self.cache, ref, newNode);
      self := self.(cache := _inout_tmp_0);
      assert replaced.lSome?;
      var lSome(node: Node) := replaced;
      oldNode := node;
      assert self.cache.contents[ref] == newNode;
      assert self.Inv();
      self.LemmaSizeEqCount();
    }
    method RemoveAndGet(inout old_self: LMutCache, ref: BT.G.Reference)
        returns (node: Node, self: LMutCache)
      requires old_self.Inv()
      requires old_self.ptr(ref).Some?
      ensures self.Inv()
      ensures node.Inv()
      ensures node == old_self.ptr(ref).value
      ensures self.I() == MapRemove1(old_self.I(), ref)
      decreases this, old_self, ref
    {
      self := old_self;
      self.LemmaSizeEqCount();
      var removed: lOption<Node>, _inout_tmp_0: LinearHashMap<Node> := LCMM.Remove(inout self.cache, ref);
      self := self.(cache := _inout_tmp_0);
      assert removed.lSome?;
      var lSome(value: Node) := removed;
      node := value;
      assert self.Inv();
    }
    method Remove(inout old_self: LMutCache, ref: BT.G.Reference) returns (self: LMutCache)
      requires old_self.Inv()
      ensures self.Inv()
      ensures self.I() == MapRemove1(old_self.I(), ref)
      decreases this, old_self, ref
    {
      self := old_self;
      self.LemmaSizeEqCount();
      var removed: lOption<Node>, _inout_tmp_0: LinearHashMap<Node> := LCMM.Remove(inout self.cache, ref);
      self := self.(cache := _inout_tmp_0);
      match removed {
        case lSome(node) =>
          {
            assert node.Inv();
            var _ := FreeNode(node);
          }
        case lNone() =>
          {
          }
      }
      assert self.Inv();
    }
    method MoveAndReplace(inout old_self: LMutCache, oldref: BT.G.Reference, newref: BT.G.Reference, node: Node)
        returns (self: LMutCache)
      requires old_self.Inv()
      requires node.Inv()
      requires |old_self.I()| <= 65536
      requires oldref in old_self.I()
      ensures self.Inv()
      ensures self.I() == old_self.I()[oldref := node.I()][newref := old_self.I()[oldref]]
      ensures newref !in old_self.I() ==> |self.I()| == |old_self.I()| + 1
      ensures newref in old_self.I() ==> |self.I()| == |old_self.I()|
      ensures self.I().Keys == old_self.I().Keys + {newref}
      decreases this, old_self, oldref, newref, node
    {
      self := old_self;
      self.LemmaSizeEqCount();
      var replaced: lOption<Node>, _inout_tmp_0: LinearHashMap<Node> := LCMM.Insert(inout self.cache, oldref, node);
      self := self.(cache := _inout_tmp_0);
      assert self.cache.contents[oldref] == node;
      assert replaced.lSome?;
      self.LemmaSizeEqCount();
      assert |self.I()| == |old_self.I()|;
      var lSome(oldnode: Node) := replaced;
      var replaced2: lOption<Node>, _inout_tmp_1: LinearHashMap<Node> := LCMM.Insert(inout self.cache, newref, oldnode);
      self := self.(cache := _inout_tmp_1);
      match replaced2 {
        case lSome(n) =>
          {
            var _ := FreeNode(n);
          }
        case lNone() =>
          {
          }
      }
      self.LemmaSizeEqCount();
    }
    method Overwrite(inout old_self: LMutCache, ref: BT.G.Reference, node: Node)
        returns (self: LMutCache)
      requires old_self.Inv()
      requires node.Inv()
      requires ref in old_self.I()
      requires |old_self.I()| <= 65536
      ensures self.Inv()
      ensures self.I() == old_self.I()[ref := node.I()]
      decreases this, old_self, ref, node
    {
      self := old_self;
      var _inout_tmp_0: LMutCache;
      _inout_tmp_0 := self.Insert(inout self, ref, node);
      self := _inout_tmp_0;
    }
    method NodeUpdateSlot(inout old_self: LMutCache, ref: BT.G.Reference, slot: uint64, bucket: MutBucket, childref: BT.G.Reference)
        returns (newchildren: Option<seq<BT.G.Reference>>, self: LMutCache)
      requires old_self.Inv()
      requires bucket.Inv()
      requires old_self.ptr(ref).Some?
      requires BT.WFNode(old_self.I()[ref])
      requires |old_self.I()| <= 65536
      requires old_self.I()[ref].children.Some?
      requires slot as int + 1 < 18446744073709551616
      requires slot as nat < |old_self.I()[ref].children.value|
      ensures self.Inv()
      ensures self.I() == old_self.I()[ref := BT.G.Node(old_self.I()[ref].pivotTable, Some(old_self.I()[ref].children.value[slot as int := childref]), old_self.I()[ref].buckets[slot as int := bucket.bucket])]
      ensures newchildren == self.I()[ref].children
      decreases this, old_self, ref, slot, bucket, childref
    {
      self := old_self;
      var node: Node, _inout_tmp_0: LMutCache := self.RemoveAndGet(inout self, ref);
      self := _inout_tmp_0;
      var _inout_tmp_1: Node;
      _inout_tmp_1 := node.UpdateSlot(inout node, slot, bucket, childref);
      node := _inout_tmp_1;
      newchildren := node.children;
      var _inout_tmp_2: LMutCache;
      _inout_tmp_2 := self.Insert(inout self, ref, node);
      self := _inout_tmp_2;
    }
    method InsertKeyValue(inout old_self: LMutCache, ref: BT.G.Reference, key: Key, msg: Message)
        returns (self: LMutCache)
      requires old_self.Inv()
      requires old_self.ptr(ref).Some?
      requires |old_self.I()| <= 65536
      requires BT.WFNode(old_self.I()[ref])
      requires Pivots.BoundedKey(old_self.I()[ref].pivotTable, key)
      requires WeightBucketList(old_self.I()[ref].buckets) + WeightKey(key) + WeightMessage(msg) < 18446744073709551616
      ensures self.Inv()
      ensures self.I() == old_self.I()[ref := BT.NodeInsertKeyValue(old_self.I()[ref], key, msg)]
      decreases this, old_self, ref, key, msg
    {
      self := old_self;
      var node: Node, _inout_tmp_0: LMutCache := self.RemoveAndGet(inout self, ref);
      self := _inout_tmp_0;
      var _inout_tmp_1: Node;
      _inout_tmp_1 := node.InsertKeyValue(inout node, key, msg);
      node := _inout_tmp_1;
      var _inout_tmp_2: LMutCache;
      _inout_tmp_2 := self.Insert(inout self, ref, node);
      self := _inout_tmp_2;
    }
    method SplitParent(inout old_self: LMutCache, ref: BT.G.Reference, slot: uint64, pivot: Key, left_childref: BT.G.Reference, right_childref: BT.G.Reference)
        returns (self: LMutCache)
      requires old_self.Inv()
      requires old_self.ptr(ref).Some?
      requires BT.WFNode(old_self.I()[ref])
      requires old_self.I()[ref].children.Some?
      requires 0 <= slot as int < |old_self.I()[ref].children.value|
      requires 0 <= slot as int < |old_self.I()[ref].buckets|
      requires |old_self.I()| <= 65536
      ensures self.Inv()
      ensures self.I() == old_self.I()[ref := BT.SplitParent(old_self.I()[ref], pivot, slot as int, left_childref, right_childref)]
      decreases this, old_self, ref, slot, pivot, left_childref, right_childref
    {
      self := old_self;
      var node: Node, _inout_tmp_0: LMutCache := self.RemoveAndGet(inout self, ref);
      self := _inout_tmp_0;
      var _inout_tmp_1: Node;
      _inout_tmp_1 := node.SplitParent(inout node, slot, pivot, left_childref, right_childref);
      node := _inout_tmp_1;
      var _inout_tmp_2: LMutCache;
      _inout_tmp_2 := self.Insert(inout self, ref, node);
      self := _inout_tmp_2;
    }
    method GetNodeInfo(ref: BT.G.Reference) returns (pivots: Pivots.PivotTable, children: Option<seq<BT.G.Reference>>)
      requires Inv()
      requires ptr(ref).Some?
      ensures pivots == I()[ref].pivotTable
      ensures children == I()[ref].children
      decreases this, ref
    {
      var node: Node := Get(ref);
      children := node.children;
      pivots := node.pivotTable;
    }
    method GetNodeBucketsLen(ref: BT.G.Reference) returns (len: uint64)
      requires Inv()
      requires ptr(ref).Some?
      ensures len as nat == |I()[ref].buckets|
      decreases this, ref
    {
      var node: Node := Get(ref);
      len := lseq_length_as_uint64(node.buckets);
    }
    method GetMessage(ref: BT.G.Reference, i: uint64, key: KeyType.Key)
        returns (msg: Option<Message>)
      requires Inv()
      requires ptr(ref).Some?
      requires BT.WFNode(I()[ref])
      requires Pivots.BoundedKey(I()[ref].pivotTable, key)
      requires i as int == Pivots.Route(I()[ref].pivotTable, key)
      ensures true && var bucket: Bucket := I()[ref].buckets[i]; true && msg == BucketsLib.bucketBinarySearchLookup(bucket, key)
      decreases this, ref, i, key
    {
      var node: Node := Get(ref);
      msg := lseq_peek(node.buckets, i).Query(key);
    }
    method NodeBucketsWeight(ref: BT.G.Reference) returns (weight: uint64)
      requires Inv()
      requires ptr(ref).Some?
      requires BT.WFNode(I()[ref])
      ensures weight as int == WeightBucketList(I()[ref].buckets)
      decreases this, ref
    {
      var node: Node := Get(ref);
      weight := MutBucket.computeWeightOfSeq(node.buckets);
    }
    method NodeBoundedBucket(ref: BT.G.Reference, pivotsref: BT.G.Reference, slot: uint64)
        returns (b: bool)
      requires Inv()
      requires ref in I()
      requires pivotsref in I()
      requires BT.WFNode(I()[ref])
      requires BT.WFNode(I()[pivotsref])
      requires slot as nat < |I()[ref].buckets|
      ensures b == Pivots.BoundedKeySeq(I()[pivotsref].pivotTable, I()[ref].buckets[slot as nat].keys)
      decreases this, ref, pivotsref, slot
    {
      var node: Node := Get(ref);
      if ref == pivotsref {
        b := node.BoundedBucket(node.pivotTable, slot);
      } else {
        var pivotsnode: Node := Get(pivotsref);
        b := node.BoundedBucket(pivotsnode.pivotTable, slot);
      }
    }
    method NodePartialFlush(parentref: BT.G.Reference, childref: BT.G.Reference, slot: uint64)
        returns (newparentBucket: MutBucket, newchild: Node)
      requires Inv()
      requires parentref in I()
      requires childref in I()
      requires BT.WFNode(I()[parentref])
      requires BT.WFNode(I()[childref])
      requires slot as nat < |I()[parentref].buckets|
      ensures newparentBucket.Inv()
      ensures newchild.Inv()
      ensures newchild.I().pivotTable == I()[childref].pivotTable
      ensures newchild.I().children == I()[childref].children
      ensures BucketFlushModel.partialFlushResult(newparentBucket.I(), newchild.I().buckets) == BucketFlushModel.partialFlush(I()[parentref].buckets[slot], I()[childref].pivotTable, I()[childref].buckets)
      decreases this, parentref, childref, slot
    {
      var parent: Node := Get(parentref);
      var child: Node := Get(childref);
      WeightBucketLeBucketList(parent.I().buckets, slot as int);
      assert WeightBucketList(child.I().buckets) <= MaxTotalBucketWeight();
      var newpbucket: MutBucket, newbuckets: lseq<MutBucket> := BucketImpl.PartialFlush(lseq_peek(parent.buckets, slot as uint64), child.buckets, child.pivotTable);
      newchild := Node(child.pivotTable, child.children, newbuckets);
      newparentBucket := newpbucket;
    }
    method NodeSplitMiddle(ref: BT.G.Reference)
        returns (left: MutBucket, right: MutBucket, pivot: Key)
      requires Inv()
      requires ref in I()
      requires BT.WFNode(I()[ref])
      requires |I()[ref].buckets| == 1
      ensures left.Inv()
      ensures right.Inv()
      ensures true && var bucket: Bucket := I()[ref].buckets[0]; pivot == BucketsLib.getMiddleKey(bucket) && left.I() == BucketsLib.SplitBucketLeft(bucket, pivot) && right.I() == BucketsLib.SplitBucketRight(bucket, pivot)
      decreases this, ref
    {
      var node: Node := Get(ref);
      var bucket: BucketImpl.MutBucket := lseq_peek(node.buckets, 0);
      pivot := bucket.GetMiddleKey();
      left, right := MutBucket.SplitLeftRight(bucket, pivot);
    }
    method NodeCutOff(ref: BT.G.Reference, lbound: KeyType.Key, ubound: Option<KeyType.Key>)
        returns (node': Node)
      requires Inv()
      requires ptr(ref).Some?
      requires BT.WFNode(I()[ref])
      requires BT.ValidSplitKey(I()[ref], lbound, ubound)
      ensures node'.Inv()
      ensures node'.I() == BT.CutoffNode(I()[ref], lbound, ubound)
      decreases this, ref, lbound, ubound
    {
      var node: Node := Get(ref);
      node' := node.CutoffNode(lbound, ubound);
    }
    method NodeBucketGen(ref: BT.G.Reference, r: uint64, start: BT.UI.RangeStart)
        returns (g: BGI.Generator)
      requires Inv()
      requires ptr(ref).Some?
      requires BT.WFNode(I()[ref])
      requires r as nat < |I()[ref].buckets|
      ensures g.Basic?
      ensures g.biter.bucket == I()[ref].buckets[r as nat]
      ensures g.Inv()
      ensures g.I() == BGI.BucketGeneratorModel.GenFromBucketWithLowerBound(I()[ref].buckets[r as nat], start)
      decreases this, ref, r, start
    {
      var node: Node := Get(ref);
      g := BGI.Generator.GenFromBucketWithLowerBound(lseq_peek(node.buckets, r), start);
    }
    method NodeBiggestSlot(ref: BT.G.Reference) returns (res: (uint64, uint64))
      requires Inv()
      requires ptr(ref).Some?
      requires biggestSlot.requires(I()[ref].buckets)
      ensures res == biggestSlot(I()[ref].buckets)
      decreases this, ref
    {
      var node: Node := Get(ref);
      var buckets: lseq<BucketImpl.MutBucket> := node.buckets;
      WeightBucketLeBucketList(MutBucket.ILseq(buckets), 0);
      var j: uint64 := 1;
      var bestIdx: uint64 := 0;
      var bestWeight: uint64 := lseq_peek(buckets, 0).weight;
      while j < lseq_length_as_uint64(buckets)
        invariant biggestSlotIterate.requires(MutBucket.ILseq(buckets), j, bestIdx, bestWeight)
        invariant biggestSlotIterate(MutBucket.ILseq(buckets), j, bestIdx, bestWeight) == biggestSlot(MutBucket.ILseq(buckets))
        decreases lseq_length_as_uint64(buckets) as int - j as int
      {
        WeightBucketLeBucketList(MutBucket.ILseq(buckets), j as int);
        var w: uint64 := lseq_peek(buckets, j).weight;
        if w > bestWeight {
          bestIdx := j;
          bestWeight := w;
        }
        j := j + 1;
      }
      return (bestIdx, bestWeight);
    }
  }
  function method CacheCount(cache: LMutCache): (c: uint64)
    requires cache.Inv()
    ensures c as int == |cache.I()|
    decreases cache
  {
    cache.LemmaSizeEqCount();
    cache.cache.count
  }
}
Dafny program verifier did not attempt verification